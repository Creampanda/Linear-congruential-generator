{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание №5. Разработка программы построения и оценки линейной многофакторной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разработать программу, которая будет считывать временные ряды отклика y и факторов Х из текстового файла и выполнять следующие операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка параметров линейной многофакторной модели (ЛМФМ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_parameters(X, y):\n",
    "    \"\"\"\n",
    "    Оценка параметров модели с помощью МНК.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)  # Добавление свободного члена\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная многофакторная модель описывает зависимость зависимой переменной y от нескольких независимых переменных (факторов) X1, X2, ..., Xn в виде:\n",
    "\n",
    "$y = b0 + b1*X1 + b2*X2 + ... + bn*Xn + e$\n",
    "\n",
    "где:\n",
    "\n",
    "$b0$ — свободный член (интерцепт),\n",
    "$b1, b2, ..., bn$ — коэффициенты модели для соответствующих факторов,\n",
    "$e$ — случайная ошибка.\n",
    "Как ваша программа оценивает параметры ЛМФМ\n",
    "В вашей программе оценка параметров модели производится с помощью функции estimate_parameters. Рассмотрим этот процесс поэтапно.\n",
    "\n",
    "\n",
    "1. Добавление свободного члена (интерцепта)\n",
    "```python\n",
    "sm.add_constant(X)\n",
    "```\n",
    "Эта функция из библиотеки statsmodels добавляет столбец единиц к матрице факторов X. Это необходимо для оценки интерцепта (b0) модели. Без этого шага модель будет принудительно проходить через начало координат, что не всегда соответствует реальности.\n",
    "\n",
    "\n",
    "2. Оценка параметров с помощью метода наименьших квадратов (МНК)\n",
    "\n",
    "```python\n",
    "model = sm.OLS(y, X).fit()\n",
    "```\n",
    "\n",
    "`sm.OLS(y, X)`: Создаёт объект модели линейной регрессии, где y — зависимая переменная, а X — матрица независимых переменных (с добавленным столбцом единиц для интерцепта).\n",
    "\n",
    "`.fit()`: Выполняет оценку параметров модели с помощью метода наименьших квадратов. Этот метод находит такие значения коэффициентов b0, b1, ..., bn, которые минимизируют сумму квадратов разностей между наблюдаемыми значениями y_i и предсказанными значениями yhat_i.\n",
    "\n",
    "\n",
    "\n",
    "### Статистические показатели: R^2, скорректированный R^2, F-статистика, p-значения для каждого коэффициента, стандартные ошибки и доверительные интервалы.\n",
    "Пример вывода model.summary()\n",
    "\n",
    "```\n",
    "                             OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   R-squared:                       0.990\n",
    "Model:                            OLS   Adj. R-squared:                  0.989\n",
    "Method:                 Least Squares   F-statistic:                     3751.\n",
    "Date:                Wed, 16 Oct 2024   Prob (F-statistic):          7.06e-191\n",
    "Time:                        21:59:12   Log-Likelihood:                -412.04\n",
    "No. Observations:                 200   AIC:                             836.1\n",
    "Df Residuals:                     194   BIC:                             855.9\n",
    "Df Model:                           5                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         -0.2048      0.551     -0.372      0.710      -1.291       0.881\n",
    "X1             2.4332      0.046     53.336      0.000       2.343       2.523\n",
    "X2             1.5882      0.047     33.675      0.000       1.495       1.681\n",
    "X3             2.9998      0.046     65.509      0.000       2.909       3.090\n",
    "X4             4.5110      0.050     89.598      0.000       4.412       4.610\n",
    "X5             1.9700      0.048     40.894      0.000       1.875       2.065\n",
    "==============================================================================\n",
    "Omnibus:                        7.061   Durbin-Watson:                   1.941\n",
    "Prob(Omnibus):                  0.029   Jarque-Bera (JB):                6.774\n",
    "Skew:                          -0.410   Prob(JB):                       0.0338\n",
    "Kurtosis:                       3.373   Cond. No.                         47.2\n",
    "==============================================================================\n",
    "```\n",
    "$coef$: Оценённые значения коэффициентов (b).\n",
    "\n",
    "$const$: Значение интерцепта (b0).\n",
    "$X1, X2, X3$: Коэффициенты для соответствующих факторов.\n",
    "$std err$: Стандартная ошибка оценки коэффициента.\n",
    "\n",
    "$t$: t-статистика для проверки гипотезы о значимости коэффициента.\n",
    "\n",
    "$P>|t|$: p-значение для проверки гипотезы.\n",
    "\n",
    "$[0.025 0.975]$: 95% доверительный интервал для коэффициента.\n",
    "\n",
    "### Какие параметры оцениваются?\n",
    "В данной модели оцениваются следующие параметры:\n",
    "\n",
    "- Свободный член (b0):\n",
    "\n",
    "Представляет собой базовое значение зависимой переменной y, когда все независимые переменные X1, X2, ..., Xn равны нулю.\n",
    "Оценён автоматически благодаря добавлению столбца единиц с помощью sm.add_constant(X).\n",
    "\n",
    "\n",
    "- Коэффициенты факторов (b1, b2, ..., bn):\n",
    "\n",
    "Отражают изменение зависимой переменной y при изменении соответствующего фактора Xi на единицу, при условии, что остальные факторы остаются неизменными.\n",
    "Эти коэффициенты показывают влияние каждого фактора на y.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор значимых факторов (решение об отсеве факторов, возврате к повторной процедуре отсева и т.д. принимает пользователь)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Отбор значимых факторов по статистической значимости (критерий выбирается разработчиком, но уровень значимости - пользователем);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_significant_factors(model, significance_level):\n",
    "    \"\"\"\n",
    "    Отбор значимых факторов по статистической значимости.\n",
    "    Возвращает список значимых факторов.\n",
    "    \"\"\"\n",
    "    p_values = model.pvalues\n",
    "    significant = p_values[p_values < significance_level].index.tolist()\n",
    "    if \"const\" in significant:\n",
    "        significant.remove(\"const\")\n",
    "    return significant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание:\n",
    "\n",
    "`model.pvalues`: Получает p-значения для всех коэффициентов модели, включая свободный член (const).\n",
    "\n",
    "`Отбор`: Факторы с p-значением меньше заданного уровня значимости (significance_level) считаются значимыми.\n",
    "\n",
    "`Исключение интерцепта`: Свободный член (const) удаляется из списка значимых факторов, так как он не является фактором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Отбор по коэффициенту корреляции - связь между факторами (между собой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multicollinearity(X, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Проверка мультиколлинеарности между факторами.\n",
    "    Возвращает пары факторов с коэффициентом корреляции выше порога.\n",
    "    \"\"\"\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr = [\n",
    "        (column, row)\n",
    "        for column in upper.columns\n",
    "        for row in upper.index\n",
    "        if upper.loc[row, column] > threshold\n",
    "    ]\n",
    "    return high_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание:\n",
    "\n",
    "`X.corr().abs()`: Вычисляет абсолютные значения коэффициентов корреляции между всеми парами факторов.\n",
    "\n",
    "`upper`: Извлекает верхнюю треугольную часть матрицы корреляции, чтобы избежать повторений и самокорреляции.\n",
    "\n",
    "`Отбор`: Создаёт список пар факторов, где коэффициент корреляции превышает заданный порог (threshold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Отбор по коэффициенту корреляции - связь между факторами и откликом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correlation_with_response(X, y, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Проверка корреляции между факторами и откликом.\n",
    "    \n",
    "    Эта функция вычисляет коэффициент корреляции между каждым фактором в X и зависимой переменной y.\n",
    "    Она возвращает список факторов, коэффициент корреляции которых по абсолютной величине превышает заданный порог.\n",
    "    \n",
    "    Параметры:\n",
    "    - X (pd.DataFrame): DataFrame, содержащий независимые переменные (факторы).\n",
    "    - y (pd.Series): Series, содержащий зависимую переменную (отклик).\n",
    "    - threshold (float): Пороговое значение для коэффициента корреляции. Факторы с |corr| > threshold будут отобраны.\n",
    "    \n",
    "    Возвращает:\n",
    "    - significant_corr (list): Список названий факторов, удовлетворяющих условию корреляции.\n",
    "    \"\"\"\n",
    "    # Вычисление коэффициентов корреляции между каждым фактором и откликом y\n",
    "    correlations = X.apply(lambda col: col.corr(y))\n",
    "    \n",
    "    # Отбор факторов, абсолютное значение корреляции которых превышает порог threshold\n",
    "    significant_corr = correlations[correlations.abs() > threshold].index.tolist()\n",
    "    \n",
    "    return significant_corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерии для Исключения Факторов\n",
    "- Статистическая Значимость (p-значение):\n",
    "\n",
    "Что: Показывает, насколько фактор важен для модели.\n",
    "Как: Если p-значение фактора выше выбранного уровня значимости (например, 0.05), фактор считается статистически незначимым и может быть исключен.\n",
    "\n",
    "- Мультиколлинеарность (Корреляция между Факторами):\n",
    "\n",
    "Что: Означает сильную взаимосвязь между двумя или более факторами.\n",
    "Как: Используйте корреляционную матрицу или фактор инфляции дисперсии (VIF). Если корреляция между факторами превышает порог (например, 0.8), один из них следует удалить, чтобы избежать искажений в модели.\n",
    "\n",
    "- Корреляция с Откликом:\n",
    "\n",
    "Что: Показывает, насколько сильно фактор связан с зависимой переменной.\n",
    "Как: Факторы с низкой корреляцией с откликом (например, ниже 0.3) могут иметь малое влияние на модель и быть кандидатами на исключение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка адекватности модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка коэффициента детерминации на статистическую значимость (F - статистика) и сообщение: адекватна модель или нет;\n",
    "Коэффициент детерминации $R^2$ показывает, какая доля вариации зависимой переменной объясняется моделью.\n",
    "\n",
    "F-статистика используется для проверки общей значимости модели. Если p-значение F-статистики меньше уровня значимости, модель считается адекватной.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление ошибки $(E = 1/n * sum ((yi-yit)/yit)$ или RMSE\n",
    "\n",
    "RMSE (Root Mean Squared Error) измеряет среднюю величину ошибок предсказания модели. Чем ниже значение RMSE, тем точнее модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_adadequacy(model, X, y):\n",
    "    \"\"\"\n",
    "    Оценка адекватности модели.\n",
    "    Возвращает R^2, F-статистику, p-значение F-статистики и RMSE.\n",
    "    \"\"\"\n",
    "    r_squared = model.rsquared  # Коэффициент детерминации R^2\n",
    "    f_stat = model.fvalue        # F-статистика\n",
    "    f_pvalue = model.f_pvalue    # p-значение для F-статистики\n",
    "    predictions = model.predict(X)  # Предсказанные значения y\n",
    "    rmse = sqrt(mean_squared_error(y, predictions))  # RMSE\n",
    "    return r_squared, f_stat, f_pvalue, rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление и вывод пользователю специальных показателей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_metrics(y, predictions):\n",
    "    \"\"\"\n",
    "    Вычисление специальных показателей.\n",
    "    Здесь вычисляется относительная ошибка.\n",
    "    \"\"\"\n",
    "    relative_error = np.mean(np.abs((y - predictions) / y))  # Относительная ошибка\n",
    "    return relative_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция special_metrics рассчитывает относительную ошибку как среднее значение абсолютных относительных отклонений предсказанных значений от фактических. Это значение также выводится пользователю для дополнительной оценки точности модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выполнения предсказания с помощью построенной модели на основе ввода значений факторов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new(model, new_data_path):\n",
    "    \"\"\"\n",
    "    Предсказание новых значений отклика на основе введённых факторов.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Чтение новых данных из файла CSV\n",
    "        new_data = pd.read_csv(new_data_path, sep=None, engine=\"python\")\n",
    "        \n",
    "        # Добавление столбца единиц для свободного члена (интерцепта)\n",
    "        X_new = sm.add_constant(new_data)\n",
    "        \n",
    "        # Выполнение предсказания с помощью модели\n",
    "        predictions = model.predict(X_new)\n",
    "        \n",
    "        # Возврат предсказанных значений\n",
    "        return predictions\n",
    "    except Exception as e:\n",
    "        # Вывод ошибки и завершение программы в случае исключения\n",
    "        print(f\"Ошибка при чтении файла с новыми данными: {e}\")\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полный код программы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры модели:\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.990\n",
      "Model:                            OLS   Adj. R-squared:                  0.989\n",
      "Method:                 Least Squares   F-statistic:                     3751.\n",
      "Date:                Thu, 17 Oct 2024   Prob (F-statistic):          7.06e-191\n",
      "Time:                        00:18:01   Log-Likelihood:                -412.04\n",
      "No. Observations:                 200   AIC:                             836.1\n",
      "Df Residuals:                     194   BIC:                             855.9\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.2048      0.551     -0.372      0.710      -1.291       0.881\n",
      "X1             2.4332      0.046     53.336      0.000       2.343       2.523\n",
      "X2             1.5882      0.047     33.675      0.000       1.495       1.681\n",
      "X3             2.9998      0.046     65.509      0.000       2.909       3.090\n",
      "X4             4.5110      0.050     89.598      0.000       4.412       4.610\n",
      "X5             1.9700      0.048     40.894      0.000       1.875       2.065\n",
      "==============================================================================\n",
      "Omnibus:                        7.061   Durbin-Watson:                   1.941\n",
      "Prob(Omnibus):                  0.029   Jarque-Bera (JB):                6.774\n",
      "Skew:                          -0.410   Prob(JB):                       0.0338\n",
      "Kurtosis:                       3.373   Cond. No.                         47.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Значимые факторы (p < 0.05): ['X1', 'X2', 'X3', 'X4', 'X5']\n",
      "Мультиколлинеарности между факторами не обнаружено.\n",
      "Коэффициент детерминации R^2: 0.9897620975121254\n",
      "F-статистика: 3751.0387922675823, p-значение: 7.058135919128105e-191\n",
      "RMSE: 1.898844671791363\n",
      "Модель адекватна.\n",
      "Относительная ошибка: 0.024724024385834733\n",
      "Предсказанные значения для новых данных:\n",
      "0      60.223969\n",
      "1      66.352848\n",
      "2      60.435731\n",
      "3      46.202399\n",
      "4      78.349259\n",
      "5      51.924627\n",
      "6      36.952918\n",
      "7      89.348472\n",
      "8      77.532742\n",
      "9      51.479849\n",
      "10     67.895967\n",
      "11     84.836578\n",
      "12    101.684011\n",
      "13     22.691974\n",
      "14     72.738586\n",
      "15     64.708120\n",
      "16     57.041787\n",
      "17     82.525183\n",
      "18     85.726109\n",
      "19     32.860691\n",
      "dtype: float64\n",
      "Результаты сохранены в файл 'output.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def read_data(file_path):\n",
    "    \"\"\"\n",
    "    Чтение данных из текстового файла.\n",
    "    Предполагается, что первый столбец — отклик y,\n",
    "    а остальные — факторы X1, X2, ..., Xn.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(\n",
    "            file_path, sep=None, engine=\"python\"\n",
    "        )  # Автоматическое определение разделителя\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении файла: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def estimate_parameters(X, y):\n",
    "    \"\"\"\n",
    "    Оценка параметров модели с помощью МНК.\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(X)  # Добавление свободного члена\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model\n",
    "\n",
    "\n",
    "def select_significant_factors(model, significance_level):\n",
    "    \"\"\"\n",
    "    Отбор значимых факторов по статистической значимости.\n",
    "    Возвращает список значимых факторов.\n",
    "    \"\"\"\n",
    "    p_values = model.pvalues\n",
    "    significant = p_values[p_values < significance_level].index.tolist()\n",
    "    if \"const\" in significant:\n",
    "        significant.remove(\"const\")\n",
    "    return significant\n",
    "\n",
    "\n",
    "def check_multicollinearity(X, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Проверка мультиколлинеарности между факторами.\n",
    "    Возвращает пары факторов с коэффициентом корреляции выше порога.\n",
    "    \"\"\"\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr = [\n",
    "        (column, row)\n",
    "        for column in upper.columns\n",
    "        for row in upper.index\n",
    "        if upper.loc[row, column] > threshold\n",
    "    ]\n",
    "    return high_corr\n",
    "\n",
    "\n",
    "def evaluate_model_adadequacy(model, X, y):\n",
    "    \"\"\"\n",
    "    Оценка адекватности модели.\n",
    "    Возвращает информацию о R^2, F-статистике и RMSE.\n",
    "    \"\"\"\n",
    "    r_squared = model.rsquared\n",
    "    f_stat = model.fvalue\n",
    "    f_pvalue = model.f_pvalue\n",
    "    predictions = model.predict(X)\n",
    "    rmse = sqrt(mean_squared_error(y, predictions))\n",
    "    return r_squared, f_stat, f_pvalue, rmse\n",
    "\n",
    "\n",
    "def special_metrics(y, predictions):\n",
    "    \"\"\"\n",
    "    Вычисление специальных показателей.\n",
    "    Здесь можно добавить любые дополнительные метрики.\n",
    "    \"\"\"\n",
    "    relative_error = np.mean(np.abs((y - predictions) / y))\n",
    "    return relative_error\n",
    "\n",
    "\n",
    "def predict_new(model, new_data_path):\n",
    "    \"\"\"\n",
    "    Предсказание новых значений отклика на основе введённых факторов.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        new_data = pd.read_csv(new_data_path, sep=None, engine=\"python\")\n",
    "        X_new = sm.add_constant(new_data)\n",
    "        predictions = model.predict(X_new)\n",
    "        return predictions\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении файла с новыми данными: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Пути к файлам (можно заменить на ввод пользователя)\n",
    "    data_file = \"data.csv\"  # Входные данные: первый столбец y, остальные X\n",
    "    new_data_file = \"new_data.csv\"  # Новые факторы для предсказания\n",
    "    output_file = \"output.txt\"  # Файл для сохранения результатов\n",
    "\n",
    "    # Чтение данных\n",
    "    data = read_data(data_file)\n",
    "    y = data.iloc[:, 0]\n",
    "    X = data.iloc[:, 1:]\n",
    "\n",
    "    # Ввод уровня значимости\n",
    "    try:\n",
    "        significance_level = float(\n",
    "            input(\"Введите уровень значимости (например, 0.05): \")\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(\"Некорректный ввод. Используется уровень значимости 0.05.\")\n",
    "        significance_level = 0.05\n",
    "\n",
    "    # Оценка параметров модели\n",
    "    model = estimate_parameters(X, y)\n",
    "    print(\"Параметры модели:\\n\", model.summary())\n",
    "\n",
    "    # Отбор значимых факторов\n",
    "    significant_factors = select_significant_factors(model, significance_level)\n",
    "    print(f\"Значимые факторы (p < {significance_level}): {significant_factors}\")\n",
    "\n",
    "    # Проверка мультиколлинеарности\n",
    "    if significant_factors:\n",
    "        high_corr = check_multicollinearity(X[significant_factors])\n",
    "        if high_corr:\n",
    "            print(\"Факторы с высокой корреляцией между собой:\")\n",
    "            for pair in high_corr:\n",
    "                print(f\"{pair[0]} и {pair[1]}\")\n",
    "        else:\n",
    "            print(\"Мультиколлинеарности между факторами не обнаружено.\")\n",
    "    else:\n",
    "        print(\"Нет значимых факторов для проверки мультиколлинеарности.\")\n",
    "\n",
    "    # Оценка адекватности модели\n",
    "    X_with_const = sm.add_constant(X)\n",
    "    r2, f_stat, f_pval, rmse = evaluate_model_adadequacy(model, X_with_const, y)\n",
    "    print(f\"Коэффициент детерминации R^2: {r2}\")\n",
    "    print(f\"F-статистика: {f_stat}, p-значение: {f_pval}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "\n",
    "    if f_pval < significance_level:\n",
    "        print(\"Модель адекватна.\")\n",
    "    else:\n",
    "        print(\"Модель неадекватна.\")\n",
    "\n",
    "    # Вычисление специальных показателей\n",
    "    predictions = model.predict(X_with_const)\n",
    "    rel_error = special_metrics(y, predictions)\n",
    "    print(f\"Относительная ошибка: {rel_error}\")\n",
    "\n",
    "    # Предсказание на новых данных\n",
    "    user_choice = (\n",
    "        input(\"Хотите выполнить предсказание на новых данных? (да/нет): \")\n",
    "        .strip()\n",
    "        .lower()\n",
    "    )\n",
    "    if user_choice == \"да\":\n",
    "        predictions_new = predict_new(model, new_data_file)\n",
    "        print(\"Предсказанные значения для новых данных:\")\n",
    "        print(predictions_new)\n",
    "    else:\n",
    "        print(\"Предсказание не выполнено.\")\n",
    "\n",
    "    # Сохранение результатов в файл\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Параметры модели:\\n\")\n",
    "        f.write(model.summary().as_text())\n",
    "        f.write(\"\\nЗначимые факторы:\\n\")\n",
    "        f.write(\n",
    "            \", \".join(significant_factors)\n",
    "            if significant_factors\n",
    "            else \"Нет значимых факторов.\"\n",
    "        )\n",
    "        f.write(\"\\nМультиколлинеарность:\\n\")\n",
    "        if significant_factors and high_corr:\n",
    "            for pair in high_corr:\n",
    "                f.write(f\"{pair[0]} и {pair[1]}\\n\")\n",
    "        elif significant_factors:\n",
    "            f.write(\"Мультиколлинеарность не обнаружена.\\n\")\n",
    "        else:\n",
    "            f.write(\"Нет значимых факторов для проверки мультиколлинеарности.\\n\")\n",
    "        f.write(f\"\\nКоэффициент детерминации R^2: {r2}\\n\")\n",
    "        f.write(f\"F-статистика: {f_stat}, p-значение: {f_pval}\\n\")\n",
    "        f.write(f\"RMSE: {rmse}\\n\")\n",
    "        f.write(f\"Относительная ошибка: {rel_error}\\n\")\n",
    "        if user_choice == \"да\":\n",
    "            f.write(\"\\nПредсказанные значения для новых данных:\\n\")\n",
    "            f.write(predictions_new.to_string())\n",
    "    print(f\"Результаты сохранены в файл '{output_file}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат работы программы\n",
    "```sh\n",
    "Параметры модели:\n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   R-squared:                       0.990\n",
    "Model:                            OLS   Adj. R-squared:                  0.989\n",
    "Method:                 Least Squares   F-statistic:                     3751.\n",
    "Date:                Thu, 17 Oct 2024   Prob (F-statistic):          7.06e-191\n",
    "Time:                        00:13:47   Log-Likelihood:                -412.04\n",
    "No. Observations:                 200   AIC:                             836.1\n",
    "Df Residuals:                     194   BIC:                             855.9\n",
    "Df Model:                           5                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         -0.2048      0.551     -0.372      0.710      -1.291       0.881\n",
    "X1             2.4332      0.046     53.336      0.000       2.343       2.523\n",
    "X2             1.5882      0.047     33.675      0.000       1.495       1.681\n",
    "X3             2.9998      0.046     65.509      0.000       2.909       3.090\n",
    "X4             4.5110      0.050     89.598      0.000       4.412       4.610\n",
    "X5             1.9700      0.048     40.894      0.000       1.875       2.065\n",
    "==============================================================================\n",
    "Omnibus:                        7.061   Durbin-Watson:                   1.941\n",
    "Prob(Omnibus):                  0.029   Jarque-Bera (JB):                6.774\n",
    "Skew:                          -0.410   Prob(JB):                       0.0338\n",
    "Kurtosis:                       3.373   Cond. No.                         47.2\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "Значимые факторы:\n",
    "X1, X2, X3, X4, X5\n",
    "Мультиколлинеарность:\n",
    "Мультиколлинеарность не обнаружена.\n",
    "\n",
    "Коэффициент детерминации R^2: 0.9897620975121254\n",
    "F-статистика: 3751.0387922675823, p-значение: 7.058135919128105e-191\n",
    "RMSE: 1.898844671791363\n",
    "Относительная ошибка: 0.024724024385834733\n",
    "\n",
    "Предсказанные значения для новых данных:\n",
    "0      60.223969\n",
    "1      66.352848\n",
    "2      60.435731\n",
    "3      46.202399\n",
    "4      78.349259\n",
    "5      51.924627\n",
    "6      36.952918\n",
    "7      89.348472\n",
    "8      77.532742\n",
    "9      51.479849\n",
    "10     67.895967\n",
    "11     84.836578\n",
    "12    101.684011\n",
    "13     22.691974\n",
    "14     72.738586\n",
    "15     64.708120\n",
    "16     57.041787\n",
    "17     82.525183\n",
    "18     85.726109\n",
    "19     32.860691\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для генерации исходных данных использовался следующий скрипт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "def generate_data(\n",
    "    n_samples=100,\n",
    "    n_factors=3,\n",
    "    coefficients=None,\n",
    "    noise_level=1.0,\n",
    "    output_file=\"data.csv\",\n",
    "    new_data_file=\"new_data.csv\",\n",
    "    n_new_samples=10,\n",
    "    random_state=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Генерация синтетических данных для линейной многофакторной модели.\n",
    "\n",
    "    Параметры:\n",
    "    - n_samples (int): Количество наблюдений.\n",
    "    - n_factors (int): Количество факторов.\n",
    "    - coefficients (list или array): Коэффициенты для факторов. Длина должна быть равна n_factors.\n",
    "                                       Если None, коэффициенты генерируются случайно.\n",
    "    - noise_level (float): Стандартное отклонение шума.\n",
    "    - output_file (str): Имя выходного файла для исходных данных.\n",
    "    - new_data_file (str): Имя выходного файла для новых данных.\n",
    "    - n_new_samples (int): Количество новых наблюдений для предсказания.\n",
    "    - random_state (int или None): Сид для генератора случайных чисел для воспроизводимости.\n",
    "\n",
    "    Возвращает:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Генерация коэффициентов, если они не заданы\n",
    "    if coefficients is None:\n",
    "        coefficients = np.random.uniform(1, 10, size=n_factors)\n",
    "    else:\n",
    "        coefficients = np.array(coefficients)\n",
    "        if len(coefficients) != n_factors:\n",
    "            raise ValueError(\"Длина списка коэффициентов должна совпадать с n_factors.\")\n",
    "\n",
    "    # Генерация факторов X\n",
    "    X = np.random.uniform(0, 10, size=(n_samples, n_factors))\n",
    "    X_df = pd.DataFrame(X, columns=[f\"X{i+1}\" for i in range(n_factors)])\n",
    "\n",
    "    # Генерация отклика y\n",
    "    y = X @ coefficients + np.random.normal(0, noise_level, size=n_samples)\n",
    "    data = pd.concat([pd.Series(y, name=\"y\"), X_df], axis=1)\n",
    "\n",
    "    # Сохранение исходных данных\n",
    "    data.to_csv(output_file, index=False)\n",
    "    print(f\"Исходные данные сохранены в файл '{output_file}'.\")\n",
    "\n",
    "    # Генерация новых данных для предсказания\n",
    "    X_new = np.random.uniform(0, 10, size=(n_new_samples, n_factors))\n",
    "    X_new_df = pd.DataFrame(X_new, columns=[f\"X{i+1}\" for i in range(n_factors)])\n",
    "    X_new_df.to_csv(new_data_file, index=False)\n",
    "    print(f\"Новые данные для предсказания сохранены в файл '{new_data_file}'.\")\n",
    "\n",
    "    # Дополнительно: вывод коэффициентов для справки\n",
    "    print(\"Использованные коэффициенты модели:\")\n",
    "    for i, coef in enumerate(coefficients, start=1):\n",
    "        print(f\"X{i}: {coef:.4f}\")\n",
    "    print(f\"Уровень шума (стд. отклонение): {noise_level}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Линейная Многофакторная Модель (ЛМФМ)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--generate\", action=\"store_true\", help=\"Сгенерировать синтетические данные.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n_samples\",\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help=\"Количество наблюдений для исходных данных.\",\n",
    "    )\n",
    "    parser.add_argument(\"--n_factors\", type=int, default=3, help=\"Количество факторов.\")\n",
    "    parser.add_argument(\n",
    "        \"--coefficients\", type=float, nargs=\"+\", help=\"Коэффициенты для факторов.\"\n",
    "    )\n",
    "    parser.add_argument(\"--noise_level\", type=float, default=1.0, help=\"Уровень шума.\")\n",
    "    parser.add_argument(\n",
    "        \"--output_file\",\n",
    "        type=str,\n",
    "        default=\"data.csv\",\n",
    "        help=\"Имя файла для исходных данных.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--new_data_file\",\n",
    "        type=str,\n",
    "        default=\"new_data.csv\",\n",
    "        help=\"Имя файла для новых данных.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--n_new_samples\",\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help=\"Количество новых наблюдений для предсказания.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--random_state\",\n",
    "        type=int,\n",
    "        default=None,\n",
    "        help=\"Сид для генератора случайных чисел.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.generate:\n",
    "        generate_data(\n",
    "            n_samples=args.n_samples,\n",
    "            n_factors=args.n_factors,\n",
    "            coefficients=args.coefficients,\n",
    "            noise_level=args.noise_level,\n",
    "            output_file=args.output_file,\n",
    "            new_data_file=args.new_data_file,\n",
    "            n_new_samples=args.n_new_samples,\n",
    "            random_state=args.random_state,\n",
    "        )\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования\n",
    "\n",
    "```sh\n",
    "python generate_data.py --generate --n_samples 200 --n_factors 5 --coefficients 2.5 1.5 3.0 4.5 2.0 --noise_level 2.0 --output_file data.csv --new_data_file new_data.csv --n_new_samples 20 --random_state 21\n",
    "\n",
    "Исходные данные сохранены в файл 'data.csv'.\n",
    "Новые данные для предсказания сохранены в файл 'new_data.csv'.\n",
    "Использованные коэффициенты модели:\n",
    "X1: 2.5000\n",
    "X2: 1.5000\n",
    "X3: 3.0000\n",
    "X4: 4.5000\n",
    "X5: 2.0000\n",
    "Уровень шума (стд. отклонение): 2.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
